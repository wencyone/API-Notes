{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5abdb71b-9a4c-4f20-9c3c-699568541ad3",
   "metadata": {},
   "source": [
    "## Making Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f82892-b122-4154-a105-9569b6392ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"Token\")\n",
    "\n",
    "response = client.chat.completions.create(    \n",
    "    model=\"gpt-4o-mini\",    \n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the OpenAI API?\"}]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81872ee-9e62-49a8-9db1-1ee312ece753",
   "metadata": {},
   "source": [
    "### Interpreting the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c01caa-8196-4049-8fec-96e9dd403d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f832f8b-38b7-4560-b831-153c320554f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06a62ff-75d5-4ddd-98e6-f4272b86f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3fea8-75cb-422c-a75a-c5c85af684dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75627eac-a057-448d-88a4-9a94df99ed77",
   "metadata": {},
   "source": [
    "### Find and replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0129de-44b1-447a-a437-66dc65c681cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "prompt=\"\"\"Replace car with plane and adjust phrase:\n",
    "A car is a vehicle that is typically powered by an internal combustion engine or an electric motor. It has four wheels, \n",
    "and is designed to carry passengers and/or cargo on roads or highways. Cars have become a ubiquitous part of modern society, \n",
    "and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods. Cars are often associated \n",
    "with freedom, independence, and mobility.\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  max_completion_tokens=100\n",
    ")\n",
    "\n",
    "# Extract and print the response text\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00c4646-1089-4a93-9286-5c38e2ae56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Use an f-string to format the prompt\n",
    "prompt = f\"\"\"Summarize the following text into two concise bullet points:\n",
    "{finance_text}\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  max_completion_tokens=400\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb3e45-37f3-4c88-ab35-fd2e418615ac",
   "metadata": {},
   "source": [
    "### Calculating the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35872f87-1015-4a13-be53-13b6a8df1774",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    max_completion_tokens=max_completion_tokens\n",
    ")\n",
    "\n",
    "input_token_price = 0.15 / 1_000_000\n",
    "output_token_price = 0.6 / 1_000_000\n",
    "\n",
    "# Extract token usage\n",
    "input_tokens = response.usage.prompt_tokens\n",
    "output_tokens = max_completion_tokens\n",
    "\n",
    "# Calculate cost\n",
    "cost = (input_tokens * input_token_price + output_tokens * output_token_price)\n",
    "print(f\"Estimated cost: ${cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c190b1-1dd6-46cb-b07e-11d58a9fc4e3",
   "metadata": {},
   "source": [
    "### How the output is generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a0b39-1a4f-4edb-81e0-048d10171137",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create( \n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages=[{\"role\": \"user\", \"content\": \"Life is like a box of chocolates.\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b608114-94b5-4061-8af9-bd56c61c3dcc",
   "metadata": {},
   "source": [
    "### Controlling response randomness\n",
    "- `temperature`: control on determinism\n",
    "- Ranges from `0 (highly deterministic)` to `2 (very random)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84162731-2bfb-465e-858c-1b80bcf24d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(  \n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages=[{\"role\": \"user\", \"content\": \"Life is like a box of chocolates.\"}],  \n",
    "    temperature=2\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee470b-8054-4c31-8983-c5cd6c9296b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation: marketing\n",
    "\n",
    "prompt = \"Generate a powerful tagline for a new electric vehicle that highlights innovation and sustainability.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8ef0d-6843-4804-b956-1096898e4e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(   \n",
    "    model=\"gpt-4o-mini\",   \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962acf82-f655-40d0-8aad-712c6e6cb44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation: product description\n",
    "\n",
    "prompt = \"\"\"Write a compelling product description for the UltraFit Smartwatch. \n",
    "Highlight its key features:  10-day battery life, 24/7 heart rate and sleep tracking, \n",
    "built-in GPS, water resistance up to 50 meters, and lightweight design.\n",
    "Use a persuasive and engaging tone to appeal to fitness enthusiasts and busy professionals.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(   \n",
    "    model=\"gpt-4o-mini\",   \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c803ce62-0712-48b8-b24a-afee2d23fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 1\n",
    "\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": \"Create a slogan for a new restaurant\"}],\n",
    "  max_completion_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa214a80-d8fd-4269-9d68-7edda7b0ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 2\n",
    "\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create a detailed prompt\n",
    "prompt = \"\"\"\n",
    "Write a compelling product description for SonicPro headphones. Highlight its best features: Active Noise Cancelling (ANC), \n",
    "40-hour battery life, and foldable design. Use a persuasive and engaging tone to appeal for tech enthuasiasts and music artists.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    # Experiment with max_completion_tokens and temperature settings\n",
    "    max_completion_tokens=300,\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cf0ed6-9779-4955-bd56-18c4a5427ef6",
   "metadata": {},
   "source": [
    "## What is Shot prompting?\n",
    "\n",
    "**Shot prompting**: including examples to guide AI responses\n",
    "- **Zero-shot**: no examples, just instructions\n",
    "- **One-shot**: one example guides the response\n",
    "- **Few-shot**: multiple examples provide more context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366c737-d1c4-4f2b-81f0-9a8eaf4a869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot prompting\n",
    "\n",
    "prompt = \"\"\"Classify sentiment as 1-5 (bad-good) in the following statements:\n",
    "1. Meal was decent, but I've had better.\n",
    "2. My food was delayed, but drinks were good.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f17ffd-efb8-411d-8ce3-8d0b1fd5b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-shot prompting\n",
    "\n",
    "prompt = \"\"\"Classify sentiment as 1-5 (bad-good) in the following statements:\n",
    "1. The service was very slow -> 1\n",
    "2. Meal was decent, but I've had better. ->\n",
    "3. My food was delayed, but drinks were good. ->\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095b7f05-1091-413b-b184-e0267db6fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot prompting\n",
    "\n",
    "prompt = \"\"\"Classify sentiment as 1-5 (bad-good) in the following statements:\n",
    "1. The service was very slow -> 1\n",
    "2. The steak was awfully good! -> 5\n",
    "3. It was ok, no massive complaints. -> 3\n",
    "4. Meal was decent, but I've had better. ->\n",
    "5. My food was delayed, but drinks were good. ->\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be863b0-779a-4986-bd18-24a98abd05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General categorization\n",
    "\n",
    "prompt = \"\"\"Classify the following animals as Land, Sea, or Both:\n",
    "1. Blue whale\n",
    "2. Polar bear\n",
    "3. Salmon\n",
    "4. Dog\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07b49a5-1d4c-473b-8179-5e03836a5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 3\n",
    "\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Define a multi-line prompt to classify sentiment\n",
    "prompt = \"\"\"Classify the sentiment as 1-5 (bad-good) in the following statements:\n",
    "1. Unbelievably good!\n",
    "2. Shoes fell apart on the second use.\n",
    "3. The shoes look nice, but they aren't very comfortable.\n",
    "4. Can't wait to show them off!\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  max_completion_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0830ad9-0010-4f0b-b0f5-07539572975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 4\n",
    "\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Add the example to the prompt\n",
    "prompt = \"\"\"Classify sentiment as 1-5 (negative to positive):\n",
    "1. Love these! = 5\n",
    "2. Unbelievably good! =\n",
    "3. Shoes fell apart on the second use. =\n",
    "4. The shoes look nice, but they aren't very comfortable. =\n",
    "5. Can't wait to show them off! =\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}], \n",
    "    max_completion_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62accd3-534d-4feb-ab55-823bcc9cffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 5\n",
    "\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Add the final example\n",
    "prompt = \"\"\"Classify sentiment as 1-5 (negative to positive):\n",
    "1. Comfortable, but not very pretty = 2\n",
    "2. Love these! = 5\n",
    "3. Unbelievably good! = \n",
    "4. Shoes fell apart on the second use. = \n",
    "5. The shoes look nice, but they aren't very comfortable. = \n",
    "6. Can't wait to show them off! = \"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    max_completion_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66b263d-ee1d-4ccf-aac8-f87fb618bd6d",
   "metadata": {},
   "source": [
    "## Chat Completions\n",
    "\n",
    "1. Single-turn tasks\n",
    "- Text generation\n",
    "- Text transformation\n",
    "- Classification\n",
    "\n",
    "2. Multi-turn conversations\n",
    "→ Build on previous prompts and responses\n",
    "\n",
    "## Roles\n",
    "\n",
    "- **System**: controls assistant's *behavior*\n",
    "- **User**: *instruct* the assistant\n",
    "- **Assistant**: *response* to user instruction\n",
    "  - Can also be written by the developer to provide examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed900839-c470-4852-8204-20ab511c93d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request setup\n",
    "\n",
    "response = client.chat.completions.create( \n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "# Prompt setup\n",
    "\n",
    "messages=[{\"role\": \"system\",\"content\": \"You are a Python programming tutor who speaks concisely.\"},     \n",
    "          {\"role\": \"user\",\"content\": \"What is the difference between mutable and immutable objects?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc25c09-d97a-4217-9b86-89f93adb8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a request\n",
    "\n",
    "response = client.chat.completions.create(  \n",
    "    model=\"gpt-4o-mini\",  \n",
    "    messages=[{\"role\": \"system\",\"content\": \"You are a Python programming tutor who speaks concisely.\"},        \n",
    "              {\"role\": \"user\",\"content\": \"What is the difference between mutable and immutable objects?\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d32cf4-ccab-4064-b3fc-cbac5c8c0fd4",
   "metadata": {},
   "source": [
    "## Mitigating misuse\n",
    "\n",
    "- **System message**: Can include *guardrails*\n",
    "- Restrictions on model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8110a46-6f48-4fa8-bfd7-4e971adeb8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg = \"\"\"You are finance education assistant that helps students study for exams.\n",
    "If you are asked for specific, real-world financial advice with risk to their finances, respond with:\n",
    "I'm sorry, I am not allowed to provide financial advice.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1695fa-b157-4672-8a6d-eb4162ba4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(  \n",
    "    model=\"gpt-4o-mini\", \n",
    "    messages=[{\"role\": \"system\",\"content\": sys_msg},   \n",
    "              {\"role\": \"user\",\"content\": \"Which stocks should I invest in?\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca41ca-da0b-4108-b358-6a1ddb82b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 6\n",
    "\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  max_completion_tokens=150,\n",
    "  messages=[\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"You are a study planning assistant that creates plans for learning new skills.\"},\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"I want to learn to speak Dutch.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "# Extract the assistant's text response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d66c7-5276-4139-9684-cf96e316c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 7\n",
    "\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "sys_msg = \"\"\"You are a study planning assistant that creates plans for learning new skills.\n",
    "\n",
    "If these skills are non related to languages, return the message:\n",
    "\n",
    "'Apologies, to focus on languages, we no longer create learning plans on other topics.'\n",
    "\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": sys_msg},\n",
    "    {\"role\": \"user\", \"content\": \"Help me learn to build new skills for rollerskating.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb26435b-b9c7-483f-9bd3-e0d26d94a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 8\n",
    "\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # Add a user and assistant message for in-context learning\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful Geography tutor that generates concise summaries for different countries.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Give me a quick summary of Portugal\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Portugal is a country in Europe that borders Spain. The capital city is Lisboa.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Give me a quick summary of Greece.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c71547-26ff-46bb-969f-7a8d38c6c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding a conversation \n",
    "\n",
    "messages = [{\"role\": \"system\",\"content\": \"You are a data science tutor who provides short, simple explanations.\"}]\n",
    "\n",
    "user_qs = [\"Why is Python so popular?\", \"Summarize this in one sentence.\"]\n",
    "\n",
    "for q in user_qs:\n",
    "    print(\"User: \", q)   \n",
    "    user_dict = {\"role\": \"user\", \"content\": q}  \n",
    "    messages.append(user_dict)   \n",
    "    response = client.chat.completions.create(  \n",
    "        model=\"gpt-4o-mini\",    \n",
    "        messages=messages  \n",
    "    )   \n",
    "    \n",
    "    assistant_dict = {\"role\": \"assistant\", \"content\": response.choices[0].message.content} \n",
    "    messages.append(assistant_dict)\n",
    "    print(\"Assistant: \", response.choices[0].message.content, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3213e01-745a-47a8-8438-3e94b0c5f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 9\n",
    "\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful math tutor that speaks concisely.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Explain what pi is.\"}\n",
    "]\n",
    "\n",
    "# Send the chat messages to the model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    max_completion_tokens=100\n",
    ")\n",
    "\n",
    "# Extract the assistant message from the response\n",
    "assistant_dict = {\"role\": \"assistant\", \"content\": response}\n",
    "\n",
    "# Add assistant_dict to the messages dictionary\n",
    "messages.append(assistant_dict)\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb2f16-7154-4221-83a2-f23abff86866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 10\n",
    "\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful math tutor that speaks concisely.\"}]\n",
    "user_msgs = [\"Explain what pi is.\", \"Summarize this in two bullet points.\"]\n",
    "\n",
    "# Loop over the user questions\n",
    "for q in user_msgs:\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    # Create a dictionary for the user message from q and append to messages\n",
    "    user_dict = {\"role\": \"user\", \"content\": q}\n",
    "    messages.append(user_dict)\n",
    "    \n",
    "    # Create the API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_completion_tokens=100\n",
    "    )\n",
    "    \n",
    "    # Append the assistant's message to messages\n",
    "    assistant_dict = {\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n",
    "    messages.append(assistant_dict)\n",
    "    print(\"Assistant: \", response.choices[0].message.content, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
